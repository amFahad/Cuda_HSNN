{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSNNHSNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q78RKmH5Te2O"
      },
      "source": [
        "MSNN : https://github.com/Nagendra1693/MSNN/blob/master/MSNN%20V1.0.ipynb   \n",
        "\n",
        "---\n",
        "\n",
        "HSNN : https://github.com/amFahad/Cuda_HSNN/blob/main/HSNN%20V1.0.ipynb\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Both these Models are combines below for classifying Scene-15 dataset. data is passed through MSNN and features extracted from this model is given to HSNN for Final classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSevaFElAKt_",
        "outputId": "75c4680a-e744-4458-8b32-247fd3ebca19"
      },
      "source": [
        "!pip install pycuda\n",
        "!pip install scikit-cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 9.1MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fb/a059825fa8c2c79894eca8aadcb798a1e5c66c0e66999a2374f313766823/pytools-2021.2.1.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (4.4.2)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp37-cp37m-linux_x86_64.whl size=621490 sha256=c676fca2a1e998d98035d96cdf9cb9be3a8893be384e11bb88c99ebf86c68481\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2021.2.1-py2.py3-none-any.whl size=62786 sha256=1aff689b0d5deaace2f15300a9974dbc33fb7e99dcdc3776410f004a387bf630\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/7c/29/7c3f742ab75f8f2df376b72b43e6640167ffbf668c950429bc\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.1.4 pycuda-2020.1 pytools-2021.2.1\n",
            "Collecting scikit-cuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/8b/36d178c3b98524fe5b1cc15d075d34e2e6e291c4b0461f6e901f1e0bc736/scikit_cuda-0.5.3-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-cuda) (1.19.5)\n",
            "Requirement already satisfied: mako>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-cuda) (1.1.4)\n",
            "Requirement already satisfied: pycuda>=2016.1 in /usr/local/lib/python3.7/dist-packages (from scikit-cuda) (2020.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako>=1.0.1->scikit-cuda) (1.1.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda>=2016.1->scikit-cuda) (2021.2.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda>=2016.1->scikit-cuda) (1.4.4)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pycuda>=2016.1->scikit-cuda) (4.4.2)\n",
            "Installing collected packages: scikit-cuda\n",
            "Successfully installed scikit-cuda-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "optimum-session"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle as pkl\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import trange\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.preprocessing import normalize\n",
        "import time\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.gpuarray as gpua\n",
        "import pycuda.curandom\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import cumath\n",
        "\n",
        "import skcuda\n",
        "import skcuda.linalg as linalg\n",
        "linalg.init()\n",
        "\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy56sNaseMna"
      },
      "source": [
        "# Matrix Inverse\n",
        "def matrix_inverse(A, cuda = True, coefficient = None):\n",
        "    m, n = A.shape\n",
        "    transpose = False\n",
        "    pinv = None\n",
        "    A = np.ascontiguousarray(A)\n",
        "#     A is m-by-n and the rank of A is equal to m (m ≤ n) then A has right inverse A_P = At * inv(A * At)\n",
        "#     A is m-by-n and the rank of A is equal to n (n ≤ m) then A has left inverse A_P = A * inv(At * A)\n",
        "\n",
        "    if m > n:\n",
        "        A = np.ascontiguousarray(A.T)\n",
        "        transpose = True\n",
        "# By default this calculates the right inverse\n",
        "    At = np.ascontiguousarray(A.T)\n",
        "    if cuda:\n",
        "        A_gpu = gpua.to_gpu(A)\n",
        "        At_gpu = gpua.to_gpu(At)\n",
        "        \n",
        "        if coefficient is None:\n",
        "            inv = linalg.inv(linalg.dot(A_gpu, At_gpu))\n",
        "        else:\n",
        "            inv = linalg.inv( gpua.to_gpu(np.identity(A.shape[0])/coefficient) + linalg.dot(A_gpu, At_gpu)).get()\n",
        "        #pinv=At.dot(inv)\n",
        "        pinv = linalg.dot(At_gpu, inv).get()\n",
        "    else:\n",
        "        inv = np.linalg.inv(A.dot(At))\n",
        "        pinv = At.dot(inv)\n",
        "        \n",
        "    if transpose:\n",
        "        pinv = pinv.T\n",
        "        \n",
        "    return pinv\n",
        "\n",
        "def exp(x):\n",
        "    x_gpu = gpua.to_gpu(x)\n",
        "    x_exp = cumath.exp(x_gpu).get()\n",
        "    return x_exp\n",
        "\n",
        "#maxpooling\n",
        "def maxpool(A,B):\n",
        "  C=A\n",
        "  for i in range(len(C)):\n",
        "    for j in range(len(C[0])):\n",
        "      if(A[i][j] > B[i][j]):\n",
        "        C[i][j] = A[i][j]\n",
        "      else:\n",
        "        C[i][j] = B[i][j]\n",
        "  return C\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roman-boundary"
      },
      "source": [
        "\n",
        "class MSNN():\n",
        "    def __init__(self):        \n",
        "        self.af = []\n",
        "        self.bf = []\n",
        "        \n",
        "        self.hf = []\n",
        "        \n",
        "        self.scalers = []\n",
        "        self.act_fn = None\n",
        "    \n",
        "    def exp(self, x):\n",
        "        x_gpu = gpua.to_gpu(x)\n",
        "        x_exp = cumath.exp(x_gpu).get()\n",
        "        return x_exp\n",
        "    \n",
        "    def act(self, h):\n",
        "        if self.act_fn == 'sigmoid':\n",
        "            h = 1/ (1+ self.exp(-h))\n",
        "        elif self.act_fn == 'sine':\n",
        "            h = np.sin(h)\n",
        "        return h\n",
        "\n",
        "    def act_inv(self, h):\n",
        "        if self.act_fn == 'sigmoid':\n",
        "            h = -1 * np.log((1/h) -1)\n",
        "        elif self.act_fn == 'sine':\n",
        "            h = np.arcsin(h)\n",
        "        return h\n",
        "    \n",
        "    def fit(self,x, y, d, l_max, act_fn):\n",
        "        self.act_fn = act_fn\n",
        "        \n",
        "        instances = x.shape[0]\n",
        "        features = x.shape[1]\n",
        "        h_saved = None\n",
        "        y_scaler = MinMaxScaler(feature_range=(0.0001, 0.9999))\n",
        "        p_scaler = MinMaxScaler(feature_range=(0.0001, 0.9999))\n",
        "        \n",
        "        x_inv = matrix_inverse(x, True)\n",
        "        \n",
        "        for j in trange(l_max, file=sys.stdout):\n",
        "#             Step1\n",
        "            if j == 0:\n",
        "                af = np.random.normal(size = (features, d)) # (d, 784)\n",
        "                bf = np.random.normal(size = (1, 1))\n",
        "                \n",
        "                h = self.act(np.dot(x, af) + bf)\n",
        "#                 print('Step 1 is done')\n",
        "#             Step4\n",
        "            else:                \n",
        "                pj_norm = self.act_inv(p_scaler.fit_transform(Pj) + 0j).real\n",
        "            \n",
        "                af = np.dot(x_inv, pj_norm)\n",
        "                bf = mean_squared_error(pj_norm, Pj, squared=False)\n",
        "                \n",
        "                h = self.act(np.dot(x, af) + bf)\n",
        "                h += p_scaler.inverse_transform(h)\n",
        "#                 print('Step 4 is done')\n",
        "  \n",
        "            self.af.append(af)\n",
        "            self.bf.append(bf)\n",
        "            self.scalers.append(p_scaler)\n",
        "            \n",
        "#             Step2\n",
        "            y_norm = self.act_inv(y_scaler.fit_transform(y) + 0j).real\n",
        "            ah = np.dot(np.linalg.pinv(h), y_norm)\n",
        "            bh = mean_squared_error(np.dot(h, ah), y_norm, squared=False)\n",
        "\n",
        "#             print('Step 2 is done')\n",
        "#             Step3\n",
        "            elm_h = self.act(np.dot(h, ah) + bh)\n",
        "\n",
        "            ej = y - y_scaler.inverse_transform(elm_h)\n",
        "            e_norm = self.act_inv(y_scaler.transform(ej) + 0j).real\n",
        "            \n",
        "            Pj = np.dot(e_norm, np.linalg.pinv(ah))\n",
        "#             print('Step 3 is done')\n",
        "\n",
        "\n",
        "            \n",
        "    def transform(self, x):\n",
        "        if len(self.af) == 0:\n",
        "            raise 'There is no feature mapping model'\n",
        "            \n",
        "        feature_data = None\n",
        "        for i in range(len(self.af)):\n",
        "            h = self.act(np.dot(x, self.af[i]) + self.bf[i])  \n",
        "            if feature_data is None:\n",
        "                feature_data = h\n",
        "            else:\n",
        "                h = self.scalers[i].inverse_transform(h)\n",
        "                feature_data += h\n",
        "        return feature_data\n",
        "    \n",
        "    def fit_transform(self, x, y, d, l_max, act_fn):\n",
        "        self.fit(x, y, d, l_max, act_fn)\n",
        "        return self.transform(x)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sublime-outdoors"
      },
      "source": [
        "import random\n",
        "class ELM:\n",
        "    def __init__(self, hidden_nodes, activation):\n",
        "        self.features = None\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.activation = activation\n",
        "\n",
        "        self.input_weights = None\n",
        "        self.output_weights = None  # beta\n",
        "        self.bias = None\n",
        "\n",
        "    def hidden_layer(self, x):\n",
        "        bias = np.array([self.bias[0],]* x.shape[0])\n",
        "        h = np.dot(x, self.input_weights) + bias\n",
        "        \n",
        "        h = h + 0j\n",
        "        \n",
        "        if self.activation == 'relu':\n",
        "            h = np.maximum(h, 0, h)\n",
        "        elif self.activation == 'sigmoid':\n",
        "            h = 1 / (1 + np.exp(-h))\n",
        "        elif self.activation == 'sine':\n",
        "            h = np.sin(h)\n",
        "        return h.real\n",
        "\n",
        "    def fit(self, x_train, y_train):\n",
        "        self.features = x_train.shape[1]\n",
        "        self.input_weights = np.random.normal(size=(x_train.shape[1], self.hidden_nodes))\n",
        "        self.bias = np.random.random((1, self.hidden_nodes))\n",
        "        H = self.hidden_layer(x_train)\n",
        "        self.output_weights = np.dot(np.linalg.pinv(H), y_train)\n",
        "\n",
        "        pred = self.predict(x_train)\n",
        "        acc = self.performance(y_train, pred)\n",
        "        return pred, acc\n",
        "\n",
        "    def predict(self, x):\n",
        "        H = self.hidden_layer(x)\n",
        "        predictions = np.dot(H, self.output_weights)\n",
        "        return predictions\n",
        "\n",
        "    def evaluate(self, x_test, y_test):\n",
        "        pred = self.predict(x_test)\n",
        "        acc = self.performance(y_test, pred)\n",
        "        return pred, acc\n",
        "\n",
        "    def performance(self, y_actual, y_predicted):\n",
        "        y_actual = np.argmax(y_actual, axis=-1)\n",
        "        y_predicted = np.argmax(y_predicted, axis=-1)\n",
        "\n",
        "        correct = np.sum(y_actual == y_predicted)\n",
        "        accuracy = (correct / y_actual.shape[0]) * 100\n",
        "#         accuracy = format(accuracy, '.2f')\n",
        "        return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MygBuqDGN178"
      },
      "source": [
        "\n",
        "train = np.genfromtxt('train.csv', delimiter=',')\n",
        "test = np.genfromtxt('test.csv', delimiter=',')\n",
        "T = train.T[0][None]\n",
        "OrgT=T;\n",
        "P = train.T[1:]\n",
        "OrgP=P;\n",
        "TV_T = test.T[0][None]\n",
        "OrgTT=TV_T;\n",
        "TV_P = test.T[1:]\n",
        "NumberofTrainingData=len(P[1])\n",
        "NumberofTestingData=len(TV_P[1])\n",
        "NumberofInputNeurons=len(P);\n",
        "NumberofOutputNeurons=len(np.unique(T));        \n",
        "#ONE HOT ENCODING\n",
        "Temp_T = np.zeros((NumberofOutputNeurons,NumberofTrainingData))\n",
        "count = 0\n",
        "for i in T.T:\n",
        "  Temp_T[int(i[0]-1)][count] = 1\n",
        "  count+=1\n",
        "T = Temp_T*2-1\n",
        "count = 0\n",
        "Temp_T = np.zeros((NumberofOutputNeurons,NumberofTestingData))\n",
        "for i in TV_T.T:\n",
        "  Temp_T[int(i[0]-1)][count] = 1\n",
        "  count+=1\n",
        "TV_T = Temp_T*2-1\n",
        "(x_train, y_train), (x_test, y_test) = (P.T,T.T),(TV_P.T,TV_T.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "related-colors",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96446cb-ced0-41ac-ddb1-feec1650abfb"
      },
      "source": [
        "x_train_m = x_train\n",
        "# x_train_m = np.array(x_train, dtype=np.float64)\n",
        "y_train_m = y_train\n",
        "x_test_m = x_test\n",
        "y_test_m = y_test\n",
        "\n",
        "m = MSNN()\n",
        "\n",
        "m.fit(x = x_train_m, y = y_train_m, d = 1500, l_max = 2, act_fn = 'sigmoid')\n",
        "x_train_new = m.transform(x_train_m)\n",
        "x_test_new = m.transform(x_test_m)\n",
        "\n",
        "elm = ELM(hidden_nodes = 100, activation = 'relu')\n",
        "\n",
        "_, train_acc = elm.fit(x_train_new, y_train)\n",
        "_, test_acc = elm.evaluate(x_test_new, y_test)\n",
        "print('\\tTraining Accuracy : ', train_acc)\n",
        "print('\\tTesting Accuracy : ', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:05<00:00,  2.63s/it]\n",
            "\tTraining Accuracy :  61.0\n",
            "\tTesting Accuracy :  55.27638190954774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPYEZM3GlXFD",
        "outputId": "0ab39e8a-7f95-455b-d553-ae97054ecfea"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.preprocessing import normalize, MinMaxScaler\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "import math\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "NumberofHiddenNeurons=100\n",
        "C=256\n",
        "kkkk=2\n",
        "sn=3\n",
        "name='scene15_channel_1'\n",
        "\n",
        "def subnetwrork(P, TV_P, T, TV_T, NumberofHiddenNeurons, C, kkkk, sn, name):\n",
        "    fdafe=0\n",
        "    fdafe1=0\n",
        "    asin = np.vectorize(math.asin)\n",
        "    sin = np.vectorize(math.sin)\n",
        "    #Creating testing and trainging data\n",
        "    OrgT=T;\n",
        "    OrgP=P;\n",
        "    OrgTT=TV_T;\n",
        "    NumberofTrainingData=len(P[1])\n",
        "    NumberofTestingData=len(TV_P[1])\n",
        "    NumberofInputNeurons=len(P);\n",
        "    NumberofOutputNeurons=len(np.unique(T));\n",
        "    saveT=T\n",
        "    \n",
        "    for subnetwork in range(1,sn+1):\n",
        "        for j in range(1,kkkk+1):\n",
        "            if(j==1):\n",
        "                BiasofHiddenNeurons1 = np.random.rand(NumberofHiddenNeurons)\n",
        "                BiasofHiddenNeurons1 = normalize(BiasofHiddenNeurons1[None], norm='l2')\n",
        "                InputWeight1=np.random.rand(NumberofHiddenNeurons,NumberofInputNeurons)*2-1\n",
        "                InputWeight1 = normalize(InputWeight1, norm='l2')\n",
        "                \n",
        "                tempH=InputWeight1.dot(P);\n",
        "                ind=np.ones((1,NumberofTrainingData));\n",
        "                BiasMatrix=ind * BiasofHiddenNeurons1.T\n",
        "                tempH=tempH+BiasMatrix;\n",
        "            else:\n",
        "                PP = np.where(PP > 1, 1, PP)\n",
        "                PP = np.where(PP < -1, -1, PP)\n",
        "                YYM_PP=PP\n",
        "                PP1=asin(PP)\n",
        "                PP1=PP1.real\n",
        "                P=P_save\n",
        "                InputWeight1=matrix_inverse(P, cuda = True, coefficient = C).T.dot(PP1.T)\n",
        "                #InputWeight1=np.linalg.lstsq((np.identity(len(P))/C+P.dot(P.T)),P)[0].dot(PP1.T)\n",
        "                InputWeight1 = InputWeight1.T\n",
        "                fdafe=0\n",
        "                tempH=InputWeight1.dot(P)\n",
        "                PTV_P = np.concatenate((P,TV_P),axis=1)\n",
        "                TTV_T = np.concatenate((saveT,TV_T),axis=1)\n",
        "                YYM_H = InputWeight1.dot(PTV_P)\n",
        "                BB1=np.array(PP1.shape)\n",
        "                BB2=sum(sum(tempH-PP1))\n",
        "                BBP=BB2/BB1[1]\n",
        "                tempH = (tempH.T - BBP).T\n",
        "                YYM_tempH = (YYM_H.T - BBP).T\n",
        "                \n",
        "            \n",
        "            H = sin(tempH)\n",
        "            \n",
        "            if(j>1):\n",
        "                YYM_H = sin(YYM_tempH)\n",
        "                scaler2 = MinMaxScaler(feature_range=(-1,1))\n",
        "                YYM_H = scaler2.fit_transform(YYM_H)\n",
        "                H = YYM_H.T[0:NumberofTrainingData].T\n",
        "                fname = \"scene15_channel_1feature_\"+str(subnetwork)+\".csv\"\n",
        "                np.savetxt(fname, YYM_H, delimiter=\",\")\n",
        "                np.savetxt(\"scene15_channel_1target.csv\", TTV_T, delimiter=\",\")\n",
        "                \n",
        "            P_save=P;\n",
        "            P=H;\n",
        "            FT=np.zeros((3,17766))\n",
        "            E1=T\n",
        "            TrainingAccuracy = []\n",
        "            for i in range(1,3):\n",
        "                a=0.0000001;\n",
        "                Y2=E1;\n",
        "                \n",
        "                if(fdafe==0):\n",
        "                    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "                    Y22 = scaler.fit_transform(Y2) #scaler.inverse_transform(X)\n",
        "                else:\n",
        "                    scaler3 = MinMaxScaler(feature_range=(-1,1))\n",
        "                    Y22 = scaler3.fit_transform(Y2)\n",
        "                \n",
        "                Y22 = np.where(Y22 > 1, 1, Y22)\n",
        "                Y22 = np.where(Y22 < -1, -1, Y22)\n",
        "                Y2=Y22                \n",
        "                Y4=asin(Y2)\n",
        "                Y4=Y4.real\n",
        "                \n",
        "                if(fdafe==0):\n",
        "                    YYM = matrix_inverse(P.T, cuda = True, coefficient = C).dot(Y4.T)\n",
        "                    #YYM = np.linalg.lstsq((np.identity(len(P))/C+linalg.dot(P_gpu,PT_gpu).get()),P)[0].dot(Y4.T)\n",
        "                    YJX=YYM.T.dot(P).T;\n",
        "                else:\n",
        "                    PP = Y4.T.dot(matrix_inverse(YYM, cuda = True, coefficient = C)).T\n",
        "                    #PP = Y4.T.dot(np.linalg.lstsq(  (np.identity(len(YYM))/C+YYM.dot(YYM.T)),YYM)[0].T).T\n",
        "                    YJX=PP.T.dot(YYM);\n",
        "                    \n",
        "                BB1=np.array(Y4.shape);\n",
        "                BB2=sum(YJX-Y4.T)\n",
        "                BB=BB2/BB1[1];\n",
        "                BB=BB[0]\n",
        "                GXZ111 = (YJX.T - BB).T\n",
        "                GXZ2=sin(GXZ111.T)\n",
        "                \n",
        "                FYY = scaler.inverse_transform(GXZ2).T\n",
        "                FT1 =  FYY.T\n",
        "                E1=E1-FT1\n",
        "                if(i==1):\n",
        "                    FT=FT1\n",
        "                    fdafe=1\n",
        "                else:\n",
        "                    FT=FT+FT1\n",
        "                \n",
        "                if(subnetwork==1):\n",
        "                    FTY=FT;\n",
        "                    FTY_prev = FTY\n",
        "                else:\n",
        "                    FTY=FTY_prev-FT;\n",
        "                    \n",
        "                MissClassificationRate_Training=0;\n",
        "                for idx in range(len(saveT[0])):\n",
        "                    label_index_expected = np.where(saveT.T[idx] == np.amax(saveT.T[idx]))\n",
        "                    label_index_actual = np.where(FTY.T[idx] == np.amax(FTY.T[idx]))\n",
        "                    if(label_index_expected!=label_index_actual):\n",
        "                        MissClassificationRate_Training+=1\n",
        "                \n",
        "                TrainingAccuracy.append(1-MissClassificationRate_Training/len(saveT[0]))\n",
        "                 \n",
        "            PP=PP+P;\n",
        "        \n",
        "        T=E1\n",
        "        P=OrgP\n",
        "        outputweight=YYM\n",
        "        fdafe=0\n",
        "    i=1\n",
        "\n",
        "def featurecomb(sn):\n",
        "    for i in range(1,sn+1):\n",
        "        fname = \"scene15_channel_1feature_\"+str(i)+\".csv\"\n",
        "        if(i==1):\n",
        "            Features = np.genfromtxt(fname, delimiter=',')\n",
        "        elif(i==2):\n",
        "            Features = Features + np.genfromtxt(fname, delimiter=',')\n",
        "    return Features\n",
        "\n",
        "def lastlayer(Features,Target):\n",
        "    C2=4096\n",
        "    kkk=1\n",
        "    P = Features[:,0:1500]\n",
        "    T = Target[:,0:1500]\n",
        "    TV_P = Features[:,1500:]\n",
        "    TV_T = Target[:,1500:]\n",
        "    NumberofTrainingData=len(P[1])\n",
        "    NumberofTestingData=len(TV_P[1])\n",
        "    NumberofInputNeurons=len(P)\n",
        "    E1=T\n",
        "    \n",
        "    Y2=E1\n",
        "    scaler = MinMaxScaler(feature_range=(0.01,0.99))\n",
        "    Y22 = scaler.fit_transform(Y2)\n",
        "    scaler2 = MinMaxScaler(feature_range=(0.01,0.99))\n",
        "    chumma = scaler2.fit_transform(TV_T)\n",
        "    Y2=Y22.T\n",
        "    def sigmoid(x):\n",
        "    \t# x = -x\n",
        "        # return 1 / (1 + exp(-x))\n",
        "        return 1 / (1 + math.exp(-x))\n",
        "    sigmoid = np.vectorize(sigmoid)\n",
        "    Y4=sigmoid(Y2).T\n",
        "    YYM=matrix_inverse(P, cuda = True, coefficient = C).T.dot(Y4.T)\n",
        "    #YYM=np.linalg.lstsq((np.identity(len(P))/C2+P.dot(P.T)),P)[0].dot(Y4.T)\n",
        "    YJX=P.T.dot(YYM)\n",
        "    BB1=np.array(Y4.shape)\n",
        "    BB2=sum(YJX-Y4.T)\n",
        "    BB=BB2[0]/BB1[1]\n",
        "    GXZ111=(P.T.dot(YYM))-BB\n",
        "    GXZ2=sigmoid(GXZ111).T\n",
        "    FYY = scaler.inverse_transform(GXZ2)\n",
        "    FT1=FYY\n",
        "    TrainingAccuracy=math.sqrt(mse(E1,FT1))\n",
        "    E1=E1-FT1\n",
        "    Y=FYY\n",
        "    D_YYM=YYM\n",
        "    MissClassificationRate_Training=0\n",
        "    for idx in range(len(T[0])):\n",
        "        label_index_expected = np.where(T.T[idx] == np.amax(T.T[idx]))\n",
        "        label_index_actual = np.where(Y.T[idx] == np.amax(Y.T[idx]))\n",
        "        if(label_index_expected!=label_index_actual):\n",
        "            MissClassificationRate_Training+=1\n",
        "    TrainingAccuracy=(1-MissClassificationRate_Training/len(T[0]))*100\n",
        "    print(\"TrainingAccuracy\",TrainingAccuracy)\n",
        "    \n",
        "    GXZ1=D_YYM.T.dot(TV_P-BB)\n",
        "    GXZ2=sigmoid(GXZ1).T\n",
        "    FYY = scaler2.inverse_transform(GXZ2.T)\n",
        "    TY2=FYY\n",
        "    E1=TY2-TV_T\n",
        "    TestingAccuracy=math.sqrt(mse(TY2,TV_T))\n",
        "    MissClassificationRate_Testing=0\n",
        "    for idx in range(len(TV_T[0])):\n",
        "        label_index_expected = np.where(TV_T.T[idx] == np.amax(TV_T.T[idx]))\n",
        "        label_index_actual = np.where(TY2.T[idx] == np.amax(TY2.T[idx]))\n",
        "        if(label_index_expected!=label_index_actual):\n",
        "            MissClassificationRate_Testing+=1\n",
        "    TestingAccuracy=(1-MissClassificationRate_Testing/len(TV_T[0]))*100\n",
        "    print(\"TestingAccuracy\",TestingAccuracy)\n",
        "\n",
        "start_time = time.time()     \n",
        "subnetwrork(x_train_new.T, x_test_new.T, y_train.T, y_test.T, NumberofHiddenNeurons, C, kkkk, sn, name)\n",
        "print(\"Subspace Feature Extraction Time : \",time.time()-start_time,\"\\n\")\n",
        "\n",
        "start_time = time.time() \n",
        "Features = featurecomb(sn)\n",
        "print(\"Combining Feature Time Taken : \",time.time()-start_time,\"\\n\")\n",
        "\n",
        "Target = np.genfromtxt(\"scene15_channel_1target.csv\", delimiter=',')\n",
        "\n",
        "start_time = time.time()\n",
        "lastlayer(Features,Target)\n",
        "print(\"Final Classification Time Taken : \",time.time()-start_time)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Subspace Feature Extraction Time :  3.4086523056030273 \n",
            "\n",
            "Combining Feature Time Taken :  0.9227828979492188 \n",
            "\n",
            "TrainingAccuracy 100.0\n",
            "TestingAccuracy 90.98827470686768\n",
            "Final Classification Time Taken :  0.17957210540771484\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}