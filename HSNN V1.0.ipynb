{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HSNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZM_e9RxdmBy",
        "outputId": "ae980e68-716a-41dc-93aa-6db3e85ea487"
      },
      "source": [
        "!pip install pycuda\n",
        "!pip install scikit-cuda\n",
        "!pip install hickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2021.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2021.2.3)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.1.4)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Requirement already satisfied: scikit-cuda in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-cuda) (1.19.5)\n",
            "Requirement already satisfied: pycuda>=2016.1 in /usr/local/lib/python3.7/dist-packages (from scikit-cuda) (2021.1)\n",
            "Requirement already satisfied: mako>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-cuda) (1.1.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda>=2016.1->scikit-cuda) (2021.2.3)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda>=2016.1->scikit-cuda) (1.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako>=1.0.1->scikit-cuda) (1.1.1)\n",
            "Requirement already satisfied: hickle in /usr/local/lib/python3.7/dist-packages (4.0.4)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.19.5)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (1.15.0)\n",
            "Requirement already satisfied: h5py<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from hickle) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmphytjqeKgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913b2254-aed5-46d4-fcbe-99e65376e9f6"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.preprocessing import normalize, MinMaxScaler\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "import math\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow as tf\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.gpuarray as gpua\n",
        "import pycuda.curandom\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import cumath\n",
        "import hickle as hkl\n",
        "import skcuda\n",
        "import skcuda.linalg as linalg\n",
        "linalg.init()\n",
        "\n",
        "\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skcuda/cublas.py:284: UserWarning: creating CUBLAS context to get version number\n",
            "  warnings.warn('creating CUBLAS context to get version number')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy56sNaseMna"
      },
      "source": [
        "# Matrix Inverse\n",
        "def matrix_inverse(A, cuda = True, coefficient = None):\n",
        "    m, n = A.shape\n",
        "    transpose = False\n",
        "    pinv = None\n",
        "    \n",
        "#     A is m-by-n and the rank of A is equal to m (m ≤ n) then A has right inverse A_P = At * inv(A * At)\n",
        "#     A is m-by-n and the rank of A is equal to n (n ≤ m) then A has left inverse A_P = A * inv(At * A)\n",
        "\n",
        "    if m > n:\n",
        "        A = np.ascontiguousarray(A.T)\n",
        "        transpose = True\n",
        "# By default this calculates the right inverse\n",
        "    At = np.ascontiguousarray(A.T)\n",
        "    A = np.ascontiguousarray(A)\n",
        "    if cuda:\n",
        "        A_gpu = gpua.to_gpu(A)\n",
        "        At_gpu = gpua.to_gpu(At)\n",
        "        \n",
        "        if coefficient is None:\n",
        "            inv = linalg.inv(linalg.dot(A_gpu, At_gpu))\n",
        "        else:\n",
        "            inv = linalg.inv( gpua.to_gpu(np.identity(A.shape[0])/coefficient) + linalg.dot(A_gpu, At_gpu))\n",
        "        pinv = linalg.dot(At_gpu, inv).get()\n",
        "    else:\n",
        "        inv = np.linalg.inv(A.dot(At))\n",
        "        pinv = At.dot(inv)\n",
        "        \n",
        "    if transpose:\n",
        "        pinv = pinv.T\n",
        "        \n",
        "    return pinv\n",
        "\n",
        "def exp(x):\n",
        "    x_gpu = gpua.to_gpu(x)\n",
        "    x_exp = cumath.exp(x_gpu).get()\n",
        "    return x_exp\n",
        "\n",
        "#maxpooling\n",
        "def maxpool(A,B):\n",
        "  C=A\n",
        "  for i in range(len(C)):\n",
        "    for j in range(len(C[0])):\n",
        "      if(A[i][j] > B[i][j]):\n",
        "        C[i][j] = A[i][j]\n",
        "      else:\n",
        "        C[i][j] = B[i][j]\n",
        "  return C\n",
        "\n",
        "#avgpooling\n",
        "def avgpool(A,B):\n",
        "  C=A\n",
        "  for i in range(len(C)):\n",
        "    for j in range(len(C[0])):\n",
        "      C[i][j] = (A[i][j]+B[i][j])/2\n",
        "  return C\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAolHB3BeT7T"
      },
      "source": [
        "def subnetwrork(P, T, TV_P, TV_T, NumberofHiddenNeurons, C, kkkk, sn, name, chnl):\n",
        "    fdafe=0\n",
        "    fdafe1=0\n",
        "    asin = np.vectorize(math.asin)\n",
        "    sin = np.vectorize(math.sin)\n",
        "    saveT=T\n",
        "    OrgT=T\n",
        "    OrgP=P\n",
        "    OrgTT=TV_T\n",
        "    NumberofTrainingData=len(P[1])\n",
        "    NumberofTestingData=len(TV_P[1])\n",
        "    NumberofInputNeurons=len(P);\n",
        "    NumberofOutputNeurons=len(np.unique(T));\n",
        "    for subnetwork in range(1,sn+1):\n",
        "        for j in range(1,kkkk+1):\n",
        "            if(j==1):\n",
        "                BiasofHiddenNeurons1 = np.random.rand(NumberofHiddenNeurons)\n",
        "                BiasofHiddenNeurons1 = normalize(BiasofHiddenNeurons1[None], norm='l2')\n",
        "                InputWeight1=np.random.rand(NumberofHiddenNeurons,NumberofInputNeurons)*2-1\n",
        "                InputWeight1 = normalize(InputWeight1, norm='l2')\n",
        "                \n",
        "                tempH=InputWeight1.dot(P);\n",
        "                ind=np.ones((1,NumberofTrainingData));\n",
        "                BiasMatrix=ind * BiasofHiddenNeurons1.T\n",
        "                tempH=tempH+BiasMatrix;\n",
        "            else:\n",
        "                PP = np.where(PP > 1, 1, PP)\n",
        "                PP = np.where(PP < -1, -1, PP)\n",
        "                YYM_PP=PP\n",
        "                PP1=asin(PP)\n",
        "                PP1=PP1.real\n",
        "                P=P_save\n",
        "                InputWeight1=matrix_inverse(P, cuda = True, coefficient = C).T.dot(PP1.T)\n",
        "                #InputWeight1=np.linalg.lstsq((np.identity(len(P))/C+P.dot(P.T)),P)[0].dot(PP1.T)\n",
        "                InputWeight1 = InputWeight1.T\n",
        "                fdafe=0\n",
        "                tempH=InputWeight1.dot(P)\n",
        "                PTV_P = np.concatenate((P,TV_P),axis=1)\n",
        "                TTV_T = np.concatenate((saveT,TV_T),axis=1)\n",
        "                YYM_H = InputWeight1.dot(PTV_P)\n",
        "                BB1=np.array(PP1.shape)\n",
        "                BB2=sum(sum(tempH-PP1))\n",
        "                BBP=BB2/BB1[1]\n",
        "                tempH = (tempH.T - BBP).T\n",
        "                YYM_tempH = (YYM_H.T - BBP).T\n",
        "                \n",
        "            \n",
        "            H = sin(tempH)\n",
        "            \n",
        "            if(j>1):\n",
        "                YYM_H = sin(YYM_tempH)\n",
        "                scaler2 = MinMaxScaler(feature_range=(-1,1))\n",
        "                YYM_H = scaler2.fit_transform(YYM_H)\n",
        "                H = YYM_H.T[0:NumberofTrainingData].T\n",
        "                fname = name+str(chnl)+\"feature_\"+str(subnetwork)+\".csv\"\n",
        "                tname = name+str(chnl)+\"target.csv\"\n",
        "                np.savetxt(fname, YYM_H, delimiter=\",\")\n",
        "                np.savetxt(tname, TTV_T, delimiter=\",\")\n",
        "                \n",
        "            P_save=P;\n",
        "            P=H;\n",
        "            FT=np.zeros((3,17766))\n",
        "            E1=T\n",
        "            TrainingAccuracy = []\n",
        "            for i in range(1,3):\n",
        "                a=0.0000001;\n",
        "                Y2=E1;\n",
        "                \n",
        "                if(fdafe==0):\n",
        "                    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "                    Y22 = scaler.fit_transform(Y2) #scaler.inverse_transform(X)\n",
        "                else:\n",
        "                    scaler3 = MinMaxScaler(feature_range=(-1,1))\n",
        "                    Y22 = scaler3.fit_transform(Y2)\n",
        "                \n",
        "                Y22 = np.where(Y22 > 1, 1, Y22)\n",
        "                Y22 = np.where(Y22 < -1, -1, Y22)\n",
        "                Y2=Y22                \n",
        "                Y4=asin(Y2)\n",
        "                Y4=Y4.real\n",
        "                \n",
        "                if(fdafe==0):\n",
        "                    YYM = matrix_inverse(P.T, cuda = True, coefficient = C).dot(Y4.T)\n",
        "                    #YYM = np.linalg.lstsq((np.identity(len(P))/C+linalg.dot(P_gpu,PT_gpu).get()),P)[0].dot(Y4.T)\n",
        "                    YJX=YYM.T.dot(P).T;\n",
        "                else:\n",
        "                    PP = Y4.T.dot(matrix_inverse(YYM, cuda = True, coefficient = C)).T\n",
        "                    #PP = Y4.T.dot(np.linalg.lstsq(  (np.identity(len(YYM))/C+YYM.dot(YYM.T)),YYM)[0].T).T\n",
        "                    YJX=PP.T.dot(YYM);\n",
        "                    \n",
        "                BB1=np.array(Y4.shape);\n",
        "                BB2=sum(YJX-Y4.T)\n",
        "                BB=BB2/BB1[1];\n",
        "                BB=BB[0]\n",
        "                GXZ111 = (YJX.T - BB).T\n",
        "                GXZ2=sin(GXZ111.T)\n",
        "                \n",
        "                FYY = scaler.inverse_transform(GXZ2).T\n",
        "                FT1 =  FYY.T\n",
        "                E1=E1-FT1\n",
        "                if(i==1):\n",
        "                    FT=FT1\n",
        "                    fdafe=1\n",
        "                else:\n",
        "                    FT=FT+FT1\n",
        "                \n",
        "                if(subnetwork==1):\n",
        "                    FTY=FT;\n",
        "                    FTY_prev = FTY\n",
        "                else:\n",
        "                    FTY=FTY_prev-FT;\n",
        "                    \n",
        "                MissClassificationRate_Training=0;\n",
        "                for idx in range(len(saveT[0])):\n",
        "                    label_index_expected = np.where(saveT.T[idx] == np.amax(saveT.T[idx]))\n",
        "                    label_index_actual = np.where(FTY.T[idx] == np.amax(FTY.T[idx]))\n",
        "                    if(label_index_expected!=label_index_actual):\n",
        "                        MissClassificationRate_Training+=1\n",
        "                \n",
        "                TrainingAccuracy.append(1-MissClassificationRate_Training/len(saveT[0]))\n",
        "                 \n",
        "            PP=PP+P;\n",
        "        \n",
        "        T=E1\n",
        "        P=OrgP\n",
        "        outputweight=YYM\n",
        "        fdafe=0\n",
        "    i=1\n",
        "\n",
        "def featurecomb(name,sn,chnl):\n",
        "  first=True\n",
        "  for i in range(1,chnl+1):\n",
        "    for j in range(1,sn+1):\n",
        "      fname = name+str(i)+\"feature_\"+str(j)+\".csv\"\n",
        "      if(first==True):\n",
        "        Features = np.genfromtxt(fname, delimiter=',')\n",
        "        first=False\n",
        "      else:\n",
        "        #Features =  maxpool(Features,np.genfromtxt(fname, delimiter=','))\n",
        "        Features = Features + np.genfromtxt(fname, delimiter=',')\n",
        "  return Features\n",
        "\n",
        "def lastlayer(Features,Target,C2,No_train):\n",
        "    kkk=1\n",
        "    P = Features[:,0:No_train]\n",
        "    T = Target[:,0:No_train]\n",
        "    TV_P = Features[:,No_train:]\n",
        "    TV_T = Target[:,No_train:]\n",
        "    NumberofTrainingData=len(P[1])\n",
        "    NumberofTestingData=len(TV_P[1])\n",
        "    NumberofInputNeurons=len(P)\n",
        "    E1=T\n",
        "    \n",
        "    Y2=E1\n",
        "    scaler = MinMaxScaler(feature_range=(0.01,0.99))\n",
        "    Y22 = scaler.fit_transform(Y2)\n",
        "    scaler2 = MinMaxScaler(feature_range=(0.01,0.99))\n",
        "    chumma = scaler2.fit_transform(TV_T)\n",
        "    Y2=Y22.T\n",
        "    def sigmoid(x):\n",
        "    \t# x = -x\n",
        "        # return 1 / (1 + exp(-x))\n",
        "        return 1 / (1 + math.exp(-x))\n",
        "    sigmoid = np.vectorize(sigmoid)\n",
        "    Y4=sigmoid(Y2).T\n",
        "    YYM=matrix_inverse(P, cuda = True, coefficient = C).T.dot(Y4.T)\n",
        "    #YYM=np.linalg.lstsq((np.identity(len(P))/C2+P.dot(P.T)),P)[0].dot(Y4.T)\n",
        "    YJX=P.T.dot(YYM)\n",
        "    BB1=np.array(Y4.shape)\n",
        "    BB2=sum(YJX-Y4.T)\n",
        "    BB=BB2[0]/BB1[1]\n",
        "    GXZ111=(P.T.dot(YYM))-BB\n",
        "    GXZ2=sigmoid(GXZ111).T\n",
        "    FYY = scaler.inverse_transform(GXZ2)\n",
        "    FT1=FYY\n",
        "    TrainingAccuracy=math.sqrt(mse(E1,FT1))\n",
        "    E1=E1-FT1\n",
        "    Y=FYY\n",
        "    D_YYM=YYM\n",
        "    MissClassificationRate_Training=0\n",
        "    for idx in range(len(T[0])):\n",
        "        label_index_expected = np.where(T.T[idx] == np.amax(T.T[idx]))\n",
        "        label_index_actual = np.where(Y.T[idx] == np.amax(Y.T[idx]))\n",
        "        if(label_index_expected!=label_index_actual):\n",
        "            MissClassificationRate_Training+=1\n",
        "    TrainingAccuracy=(1-MissClassificationRate_Training/len(T[0]))*100\n",
        "    print(\"TrainingAccuracy\",TrainingAccuracy)\n",
        "    \n",
        "    GXZ1=D_YYM.T.dot(TV_P-BB)\n",
        "    GXZ2=sigmoid(GXZ1).T\n",
        "    FYY = scaler2.inverse_transform(GXZ2.T)\n",
        "    TY2=FYY\n",
        "    E1=TY2-TV_T\n",
        "    TestingAccuracy=math.sqrt(mse(TY2,TV_T))\n",
        "    MissClassificationRate_Testing=0\n",
        "    for idx in range(len(TV_T[0])):\n",
        "        label_index_expected = np.where(TV_T.T[idx] == np.amax(TV_T.T[idx]))\n",
        "        label_index_actual = np.where(TY2.T[idx] == np.amax(TY2.T[idx]))\n",
        "        if(label_index_expected!=label_index_actual):\n",
        "            MissClassificationRate_Testing+=1\n",
        "    TestingAccuracy=(1-MissClassificationRate_Testing/len(TV_T[0]))*100\n",
        "    print(\"TestingAccuracy\",TestingAccuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-t9zqfwbLcD"
      },
      "source": [
        "def loadata(traincsv,testcsv):\n",
        "  train = np.genfromtxt(traincsv, delimiter=',')\n",
        "  test = np.genfromtxt(testcsv, delimiter=',')\n",
        "  T = train.T[0][None]\n",
        "  P = train.T[1:]\n",
        "  TV_T = test.T[0][None]\n",
        "  TV_P = test.T[1:]\n",
        "  NumberofTrainingData=len(P[1])\n",
        "  NumberofTestingData=len(TV_P[1])\n",
        "  NumberofInputNeurons=len(P);\n",
        "  NumberofOutputNeurons=len(np.unique(T));        \n",
        "  #ONE HOT ENCODING\n",
        "  Temp_T = np.zeros((NumberofOutputNeurons,NumberofTrainingData))\n",
        "  count = 0\n",
        "  for i in T.T:\n",
        "    Temp_T[int(i[0]-1)][count] = 1\n",
        "    count+=1\n",
        "  T = Temp_T*2-1\n",
        "  count = 0\n",
        "  Temp_T = np.zeros((NumberofOutputNeurons,NumberofTestingData))\n",
        "  for i in TV_T.T:\n",
        "    Temp_T[int(i[0]-1)][count] = 1\n",
        "    count+=1\n",
        "  TV_T = Temp_T*2-1\n",
        "  return T, P, TV_T, TV_P, traincsv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM6A_eq-Yi4h",
        "outputId": "ef2e25d1-4b94-4968-a9dd-86b95a2e8bb8"
      },
      "source": [
        "T, P, TV_T, TV_P, repeat = loadata('Scene_15_train.csv','Scene_15_test.csv')\n",
        "NumberofHiddenNeurons=80\n",
        "C=128\n",
        "kkkk=2\n",
        "sn=3\n",
        "name='scene15_channel_'\n",
        "chnl=1\n",
        "load\n",
        "for i in range(chnl):\n",
        "  start_time = time.time()     \n",
        "  subnetwrork(P,T,TV_P,TV_T, NumberofHiddenNeurons, C, kkkk, sn, name, i+1)\n",
        "  print(\"Subspace Feature Extraction Time for channel_\"+str(i+1)+\" : \",time.time()-start_time,\"\\n\")\n",
        "\n",
        "start_time = time.time() \n",
        "Features = featurecomb(name, sn, chnl)\n",
        "print(\"Combining Feature Time Taken : \",time.time()-start_time,\"\\n\")\n",
        "\n",
        "Target = np.genfromtxt(name+str(chnl)+\"target.csv\", delimiter=',')\n",
        "\n",
        "C2=4096\n",
        "No_train = len(P[1])\n",
        "start_time = time.time()\n",
        "lastlayer(Features,Target,C2,No_train)\n",
        "print(\"Final Classification Time Taken : \",time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 1500) (15, 1500) (3000, 2985) (15, 2985)\n",
            "Subspace Feature Extraction Time for channel_1 :  4.012771844863892 \n",
            "\n",
            "Combining Feature Time Taken :  1.3897857666015625 \n",
            "\n",
            "TrainingAccuracy 97.86666666666667\n",
            "TestingAccuracy 93.96984924623115\n",
            "Final Classification Time Taken :  0.2398059368133545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95bDu44YDPWo"
      },
      "source": [
        "NumberofHiddenNeurons=100\n",
        "C=1\n",
        "kkkk=2\n",
        "sn=3\n",
        "name='c101_channel_'\n",
        "chnl=12\n",
        "repeat=None;\n",
        "\n",
        "for i in range(chnl):\n",
        "  if(i<=2 and repeat!='c101_sift_train.csv'):\n",
        "    T, P, TV_T, TV_P, repeat = loadata('c101_sift_train.csv','c101_sift_test.csv')\n",
        "  elif(i>2 and i<=6 and repeat!='c101_HMP_train.csv'):\n",
        "    T,P,TV_T,TV_P,repeat = loadata('c101_HMP_train.csv','c101_HMP_test.csv')\n",
        "  elif(i>6 and repeat!='c101_Spatial_train.csv'):\n",
        "    T,P,TV_T,TV_P,repeat = loadata('c101_Spatial_train.csv','c101_Spatial_test.csv')\n",
        "  start_time = time.time()   \n",
        "  subnetwrork(P,T,TV_P,TV_T, NumberofHiddenNeurons, C, kkkk, sn, name, i+1)\n",
        "  print(\"Subspace Feature Extraction Time for channel_\"+str(i+1)+\" : \",time.time()-start_time,\"\\n\")\n",
        "\n",
        "start_time = time.time() \n",
        "Features = featurecomb(name, sn, chnl)\n",
        "print(\"Combining Feature Time Taken : \",time.time()-start_time,\"\\n\")\n",
        "\n",
        "Target = np.genfromtxt(name+str(chnl)+\"target.csv\", delimiter=',')\n",
        "\n",
        "C2=2^-13\n",
        "No_train = len(P[1])\n",
        "print(No_train)\n",
        "start_time = time.time()\n",
        "lastlayer(Features,Target,C2,No_train)\n",
        "print(\"Final Classification Time Taken : \",time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}